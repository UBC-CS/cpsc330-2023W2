\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{03\_ml-fundamentals}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@ges}{\let\PY@bf=\textbf\let\PY@it=\textit}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/330-banner.png}

    \section{Lecture 3: Machine Learning
Fundamentals}\label{lecture-3-machine-learning-fundamentals}

UBC 2023-24

Instructors: Mathias LÃ©cuyer and Mehrdad Oveisi

    \subsubsection{Announcements}\label{announcements}

\begin{itemize}
\tightlist
\item
  hw1 is due \textbf{today}, Tue Jan 16, at 11:59pm
\item
  hw2 is released. (Due next week Monday, Jan 22, at 11:59pm)

  \begin{itemize}
  \tightlist
  \item
    You are welcome to broadly discuss it with your classmates but final
    answers and submissions must be your own.
  \item
    Group submissions are \textbf{not} allowed for this assignment.
  \end{itemize}
\item
  Advice on keeping up with the material

  \begin{itemize}
  \tightlist
  \item
    Practice!
  \item
    Make sure you run the lecture notebooks on your laptop.
  \item
    Start early on homework assignments.\\
  \end{itemize}
\item
  If you are still on the waitlist, \textbf{it's your responsibility to
  keep up with the material and submit assignments}. You can ask for
  help to submit via cpsc330-admin@cs.ubc.ca
\item
  Last day to withdraw without a W standing: Mon Jan 22, 2024
\end{itemize}

    \subsection{Imports, LOs}\label{imports-los}

    \subsubsection{Imports}\label{imports}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} import the libraries}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{sys}

\PY{k+kn}{import} \PY{n+nn}{IPython}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k+kn}{import} \PY{n}{HTML}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}

\PY{n}{sys}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../code/.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k+kn}{from} \PY{n+nn}{plotting\PYZus{}functions} \PY{k+kn}{import} \PY{o}{*}

\PY{c+c1}{\PYZsh{} Classifiers}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k+kn}{import} \PY{n}{DecisionTreeClassifier}
\PY{k+kn}{from} \PY{n+nn}{utils} \PY{k+kn}{import} \PY{o}{*}

\PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline

\PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{display.max\PYZus{}colwidth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    

    

    \subsubsection{Learning outcomes}\label{learning-outcomes}

From this lecture, you will be able to

\begin{itemize}
\tightlist
\item
  explain how decision boundaries change with the \texttt{max\_depth}
  hyperparameter;
\item
  explain the concept of generalization;
\item
  appropriately split a dataset into train and test sets using
  \texttt{train\_test\_split} function;
\item
  explain the difference between train, validation, test, and
  ``deployment'' data;
\item
  identify the difference between training error, validation error, and
  test error;
\item
  explain cross-validation and use \texttt{cross\_val\_score} and
  \texttt{cross\_validate} to calculate cross-validation error;
\item
  recognize overfitting and/or underfitting by looking at train and test
  scores;
\item
  explain why it is generally not possible to get a perfect test score
  (zero test error) on a supervised learning problem;
\item
  describe the fundamental tradeoff between training score and the
  train-test gap;
\item
  state the golden rule;
\item
  start to build a standard recipe for supervised learning: train/test
  split, hyperparameter tuning with cross-validation, test on test set.
\end{itemize}

    

    \subsection{\texorpdfstring{Generalization
{[}\href{https://youtu.be/iS2hsRRlc2M}{video}{]}}{Generalization {[}video{]}}}\label{generalization-video}

    \subsubsection{Big picture and
motivation}\label{big-picture-and-motivation}

In machine learning we want to learn a mapping function from labeled
data so that we can predict labels of \textbf{unlabeled} data. For
example, suppose we want to build a spam filtering system. We will take
a large number of spam/non-spam messages from the past, learn patterns
associated with spam/non-spam from them, and predict whether \textbf{a
new incoming message} in someone's inbox is spam or non-spam based on
these patterns.

So we want to learn from the past but ultimately we want to apply it on
the future email messages.

    \includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/eva-think.png}

\textbf{How can we generalize from what we've seen to what we haven't
seen?}

In this lecture, we'll see how machine learning tackles this question.

    \subsubsection{Model complexity and training
error}\label{model-complexity-and-training-error}

In the last lecture, we looked at decision boundaries, a way to
visualize what sort of examples will be classified as positive and
negative.

Let's examine how does the decision boundary change for different tree
depths.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Toy quiz2 grade data}
\PY{n}{classification\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../data/quiz2\PYZhy{}grade\PYZhy{}toy\PYZhy{}classification.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{classification\PYZus{}df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   ml\_experience  class\_attendance  lab1  lab2  lab3  lab4  quiz1   quiz2
0              1                 1    92    93    84    91     92      A+
1              1                 0    94    90    80    83     91  not A+
2              0                 0    78    85    83    80     80  not A+
3              0                 1    91    94    92    91     89      A+
4              0                 1    77    83    90    92     85      A+
5              1                 0    70    73    68    74     71  not A+
6              1                 0    80    88    89    88     91      A+
7              0                 1    95    93    69    79     75  not A+
8              0                 0    97    90    94    99     80  not A+
9              1                 1    95    95    94    94     85  not A+
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X} \PY{o}{=} \PY{n}{classification\PYZus{}df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quiz2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{classification\PYZus{}df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quiz2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}subset} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lab4}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quiz1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}  \PY{c+c1}{\PYZsh{} Let\PYZsq{}s consider a subset of the data for visualization}
\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   lab4  quiz1
0    91     92
1    83     91
2    80     80
3    91     89
4    92     85
\end{Verbatim}
\end{tcolorbox}
        
    In the following model, this decision boundary is created by asking one
question.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{depth} \PY{o}{=} \PY{l+m+mi}{1}
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{depth}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree\PYZus{}decision\PYZus{}boundary\PYZus{}and\PYZus{}tree}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{x\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lab4}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quiz1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Error:   0.286
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    In the following model, this decision boundary is created by asking two
questions.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{depth} \PY{o}{=} \PY{l+m+mi}{2}
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{depth}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree\PYZus{}decision\PYZus{}boundary\PYZus{}and\PYZus{}tree}\PY{p}{(}
    \PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{x\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lab4}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quiz1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{14}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Error:   0.190
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_20_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Let's look at the decision boundary with depth = 4.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{depth} \PY{o}{=} \PY{l+m+mi}{4}
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{depth}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree\PYZus{}decision\PYZus{}boundary\PYZus{}and\PYZus{}tree}\PY{p}{(}
    \PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{x\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lab4}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quiz1}\PY{l+s+s2}{\PYZdq{}}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Error:   0.048
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_22_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Let's look at the decision boundary with depth = 6.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{depth} \PY{o}{=} \PY{l+m+mi}{6}
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{depth}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{plot\PYZus{}tree\PYZus{}decision\PYZus{}boundary\PYZus{}and\PYZus{}tree}\PY{p}{(}
    \PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{x\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lab4}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quiz1}\PY{l+s+s2}{\PYZdq{}}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Error:   0.000
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_24_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{max\PYZus{}depths} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{)}
\PY{n}{errors} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{max\PYZus{}depth} \PY{o+ow}{in} \PY{n}{max\PYZus{}depths}\PY{p}{:}
    \PY{n}{error} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{max\PYZus{}depth}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{score}\PY{p}{(}
        \PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}
    \PY{p}{)}
    \PY{n}{errors}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{error}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{max\PYZus{}depths}\PY{p}{,} \PY{n}{errors}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_25_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{itemize}
\tightlist
\item
  Our model has 0\% error for depths \textgreater= 6!!
\item
  But it's also becoming more and more specific and sensitive to the
  training data.\\
\item
  Is it good or bad?
\end{itemize}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Although the plot above (complexity hyperparameter vs error) is more
popular, we could also look at the same plot flip the \(y\)-axis, i.e.,
consider accuracy instead of error. \_\_\_

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{max\PYZus{}depths} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{)}
\PY{n}{accuracies} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{max\PYZus{}depth} \PY{o+ow}{in} \PY{n}{max\PYZus{}depths}\PY{p}{:}
    \PY{n}{accuracy} \PY{o}{=} \PY{p}{(}
        \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{max\PYZus{}depth}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}subset}\PY{p}{,} \PY{n}{y}\PY{p}{)}
    \PY{p}{)}
    \PY{n}{accuracies}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{accuracy}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{max\PYZus{}depths}\PY{p}{,} \PY{n}{accuracies}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_28_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{ðŸ¤” Eva's questions}\label{evas-questions}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/eva-think.png}

    At this point Eva is wondering about the following questions.

\begin{itemize}
\tightlist
\item
  How to pick the best depth?
\item
  How can we make sure that the model we have built would do reasonably
  well on new data in the wild when it's deployed?
\item
  Which of the following rules learned by the decision tree algorithm
  are likely to generalize better to new data?
\end{itemize}

\begin{quote}
Rule 1: If class\_attendance == 1 then grade is A+.
\end{quote}

\begin{quote}
Rule 2: If lab3 \textgreater{} 83.5 and quiz1 \textless= 83.5 and lab2
\textless= 88 then quiz2 grade is A+
\end{quote}

To better understand the material in the next sections, think about
these questions on your own or discuss them with your friend/neighbour
before proceeding.

    

    \subsubsection{Generalization: Fundamental goal of
ML}\label{generalization-fundamental-goal-of-ml}

\begin{quote}
\textbf{To generalize beyond what we see in the training examples}
\end{quote}

We only have access to limited amount of training data and we want to
learn a mapping function which would predict targets reasonably well for
examples beyond this training data.

    \begin{itemize}
\tightlist
\item
  Example: Imagine that a learner sees the following images and
  corresponding labels.
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/generalization-train.png}

    \subsubsection{Generalizing to unseen
data}\label{generalizing-to-unseen-data}

\begin{itemize}
\tightlist
\item
  Now the learner is presented with new images (1 to 4) for prediction.
\item
  What prediction would you expect for each image?
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/generalization-predict.png}

    \begin{itemize}
\tightlist
\item
  Goal: We want the learner to be able to generalize beyond what it has
  seen in the training data.
\item
  But these new examples should be representative of the training data.
  That is they should have the same characteristics as the training
  data.
\item
  In this example, we would like the leaner to be able to predict labels
  for test examples 1, 2, and 3 accurately. Although 2, 3 don't exactly
  occur in the training data, they are very much similar to the images
  in the training data. That said, is it fair to expect the learner to
  label image 4 correctly?
\end{itemize}

    \subsubsection{Training error vs.~Generalization
error}\label{training-error-vs.-generalization-error}

\begin{itemize}
\tightlist
\item
  Given a model \(M\), in ML, people usually talk about two kinds of
  errors of \(M\).

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Error on the training data: \(error_{training}(M)\)
  \item
    Error on the entire distribution \(D\) of data: \(error_{D}(M)\)
  \end{enumerate}
\item
  We are interested in the error on the entire distribution

  \begin{itemize}
  \tightlist
  \item
    \ldots{} But we do not have access to the entire distribution ðŸ˜ž
  \end{itemize}
\end{itemize}

    

    \subsection{\texorpdfstring{Data Splitting
{[}\href{https://youtu.be/h2AEobwcUQw}{video}{]}}{Data Splitting {[}video{]}}}\label{data-splitting-video}

    \subsubsection{How to approximate generalization
error?}\label{how-to-approximate-generalization-error}

A common way is \textbf{data splitting}. - Keep aside some randomly
selected portion from the training data. - \texttt{fit} (train) a model
on the training portion only. - \texttt{score} (assess) the trained
model on this set aside data to get a sense of how well the model would
be able to generalize. - Pretend that the kept aside data is
representative of the real distribution \(D\) of data.

    \includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/eva-good-idea.png}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} scikit\PYZhy{}learn train\PYZus{}test\PYZus{}split}
\PY{n}{url} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{https://scikit\PYZhy{}learn.org/stable/modules/generated/sklearn.model\PYZus{}selection.train\PYZus{}test\PYZus{}split.html}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{IPython}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{IFrame}\PY{p}{(}\PY{n}{url}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{l+m+mi}{800}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<IPython.lib.display.IFrame at 0x19882b040>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{itemize}
\tightlist
\item
  We can pass \texttt{X} and \texttt{y} or a dataframe with both
  \texttt{X} and \texttt{y} in it.
\item
  We can also specify the train or test split sizes.
\end{itemize}

    \subsubsection{Simple train/test split}\label{simple-traintest-split}

\begin{itemize}
\tightlist
\item
  The picture shows an 80\%-20\% split of a toy dataset with 10
  examples.
\item
  The data is shuffled before splitting.
\item
  Usually when we do machine learning we split the data before doing
  anything and put the test data in an imaginary chest lock.
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/train-test-split.png}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s demonstrate this with the canada usa cities data}
\PY{c+c1}{\PYZsh{} The data is available in the data directory}
\PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../data/canada\PYZus{}usa\PYZus{}cities.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{X} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{country}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{country}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
     longitude  latitude
0    -130.0437   55.9773
1    -134.4197   58.3019
2    -123.0780   48.9854
3    -122.7436   48.9881
4    -122.2691   48.9951
..         {\ldots}       {\ldots}
204   -72.7218   45.3990
205   -66.6458   45.9664
206   -79.2506   42.9931
207   -72.9406   45.6275
208   -79.4608   46.3092

[209 rows x 2 columns]
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{y}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
0         USA
1         USA
2         USA
3         USA
4         USA
        {\ldots}
204    Canada
205    Canada
206    Canada
207    Canada
208    Canada
Name: country, Length: 209, dtype: object
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}

\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}
    \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} 80\PYZpc{}\PYZhy{}20\PYZpc{} train test split on X and y}

\PY{c+c1}{\PYZsh{} Print shapes}
\PY{n}{shape\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Data portion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X\PYZus{}train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y\PYZus{}train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X\PYZus{}test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y\PYZus{}test}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Shape}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{[}
        \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{,}
        \PY{n}{y}\PY{o}{.}\PY{n}{shape}\PY{p}{,}
        \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,}
        \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,}
        \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{,}
        \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{,}
    \PY{p}{]}\PY{p}{,}
\PY{p}{\PYZcb{}}

\PY{n}{shape\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{shape\PYZus{}dict}\PY{p}{)}
\PY{n}{HTML}\PY{p}{(}\PY{n}{shape\PYZus{}df}\PY{o}{.}\PY{n}{to\PYZus{}html}\PY{p}{(}\PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
\end{Verbatim}
\end{tcolorbox}
        
    \paragraph{\texorpdfstring{Creating \texttt{train\_df} and
\texttt{test\_df}}{Creating train\_df and test\_df}}\label{creating-train_df-and-test_df}

\begin{itemize}
\tightlist
\item
  Sometimes we want to keep the target in the train split for EDA or for
  visualization.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{train\PYZus{}df}\PY{p}{,} \PY{n}{test\PYZus{}df} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}
    \PY{n}{df}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}
\PY{p}{)}  \PY{c+c1}{\PYZsh{} 80\PYZpc{}\PYZhy{}20\PYZpc{} train test split on df}
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{train\PYZus{}df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{country}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{train\PYZus{}df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{country}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{test\PYZus{}df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{country}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{test\PYZus{}df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{country}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{train\PYZus{}df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
     longitude  latitude country
160   -76.4813   44.2307  Canada
127   -81.2496   42.9837  Canada
169   -66.0580   45.2788  Canada
188   -73.2533   45.3057  Canada
187   -67.9245   47.1652  Canada
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{32}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{mglearn}\PY{o}{.}\PY{n}{discrete\PYZus{}scatter}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_50_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{39}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{p}{)}
\PY{n}{custom\PYZus{}plot\PYZus{}tree}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{feature\PYZus{}names} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_51_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Let's examine the train and test accuracies with the split now.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Train accuracy:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test accuracy:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Train accuracy:   1.000
Test accuracy:   0.762
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plot\PYZus{}tree\PYZus{}decision\PYZus{}boundary\PYZus{}and\PYZus{}tree}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{l+m+mi}{18}\PY{p}{,} \PY{n}{eps}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_54_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{43}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{,} \PY{n}{subplot\PYZus{}kw}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{xticks}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yticks}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{(}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{plot\PYZus{}tree\PYZus{}decision\PYZus{}boundary}\PY{p}{(}
    \PY{n}{model}\PY{p}{,}
    \PY{n}{X\PYZus{}train}\PY{p}{,}
    \PY{n}{y\PYZus{}train}\PY{p}{,}
    \PY{n}{eps}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,}
    \PY{n}{x\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{y\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
    \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision tree model on the train data}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
\PY{p}{)}
\PY{n}{plot\PYZus{}tree\PYZus{}decision\PYZus{}boundary}\PY{p}{(}
    \PY{n}{model}\PY{p}{,}
    \PY{n}{X\PYZus{}test}\PY{p}{,}
    \PY{n}{y\PYZus{}test}\PY{p}{,}
    \PY{n}{eps}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,}
    \PY{n}{x\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{y\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
    \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision tree model on the test data}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_55_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{itemize}
\tightlist
\item
  Useful arguments of \texttt{train\_test\_split}:

  \begin{itemize}
  \tightlist
  \item
    \texttt{test\_size}
  \item
    \texttt{train\_size}
  \item
    \texttt{random\_state}
  \end{itemize}
\end{itemize}

    \paragraph{\texorpdfstring{\texttt{test\_size}, \texttt{train\_size}
arguments}{test\_size, train\_size arguments}}\label{test_size-train_size-arguments}

\begin{itemize}
\tightlist
\item
  Let's us specify how we want to split the data.
\item
  We can specify either of the two. See the documentation
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{here}.
\item
  There is no hard and fast rule on what split sizes should we use.

  \begin{itemize}
  \tightlist
  \item
    It depends upon how much data is available to you.
  \end{itemize}
\item
  Some common splits are 90/10, 80/20, 70/30 (training/test).
\item
  In the above example, we used 80/20 split.
\end{itemize}

    \paragraph{\texorpdfstring{\texttt{random\_state}
argument}{random\_state argument}}\label{random_state-argument}

\begin{itemize}
\tightlist
\item
  The data is shuffled before splitting which is crucial step. (You will
  explore this in the lab.)
\item
  The \texttt{random\_state} argument controls this shuffling.
\item
  In the example above we used \texttt{random\_state=123}. If you run
  this notebook with the same \texttt{random\_state} it should give you
  exactly the same split.

  \begin{itemize}
  \tightlist
  \item
    Useful when you want reproducible results.
  \end{itemize}
\end{itemize}

    \subsubsection{Train/validation/test
split}\label{trainvalidationtest-split}

\begin{itemize}
\tightlist
\item
  Some of you may have heard of ``validation'' data.
\item
  Sometimes it's a good idea to have a separate data for hyperparameter
  tuning.
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/train-valid-test-split.png}

    \begin{itemize}
\tightlist
\item
  We will try to use ``validation'' to refer to data where we have
  access to the target values.

  \begin{itemize}
  \tightlist
  \item
    But, unlike the training data, we only use this for hyperparameter
    tuning and model assessment; we don't pass these into
    \texttt{fit}.\\
  \end{itemize}
\item
  We will try to use ``test'' to refer to data where we have access to
  the target values

  \begin{itemize}
  \tightlist
  \item
    But, unlike training and validation data, we neither use it in
    training nor hyperparameter optimization.
  \item
    We only use it \textbf{once} to evaluate the performance of the best
    performing model on the validation set.\\
  \item
    We lock it in a ``vault'' until we're ready to evaluate.
  \end{itemize}
\end{itemize}

Note that there isn't good concensus on the terminology of what is
validation and what is test.

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Validation data is also referred to as \textbf{development data} or
\textbf{dev set} for short.\\
\_\_\_

    \subsubsection{``Deployment'' data}\label{deployment-data}

\begin{itemize}
\tightlist
\item
  After we build and finalize a model, we deploy it, and then the model
  deals with the data in the wild.
\item
  We will use ``deployment'' to refer to this data, where we do
  \textbf{not} have access to the target values.
\item
  Deployment error is what we \emph{really} care about.
\item
  We use validation and test errors as proxies for deployment error, and
  we hope they are similar.
\item
  So, if our model does well on the validation and test data, we hope it
  will do well on deployment data.
\end{itemize}

    \subsubsection{Summary of train, validation, test, and deployment
data}\label{summary-of-train-validation-test-and-deployment-data}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
& \texttt{fit} & \texttt{score} & \texttt{predict} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Train & âœ”ï¸ & âœ”ï¸ & âœ”ï¸ \\
Validation & & âœ”ï¸ & âœ”ï¸ \\
Test & & once & once \\
Deployment & & & âœ”ï¸ \\
\end{longtable}

You can typically expect
\(E_{train} < E_{validation} < E_{test} < E_{deployment}\).

    \subsection{â“â“ Questions for you}\label{questions-for-you}

    \subsubsection{iClicker Exercise 3.1}\label{iclicker-exercise-3.1}

\textbf{iClicker cloud join link: https://join.iclicker.com/WMSX}

\textbf{Select all of the following statements which are TRUE.}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \tightlist
  \item
    A decision tree model with no depth (the default \texttt{max\_depth}
    in \texttt{sklearn}) is likely to perform very well on the
    deployment data.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{1}
  \tightlist
  \item
    Data splitting helps us assess how well our model would generalize.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{2}
  \tightlist
  \item
    Deployment data is only scored once.\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{3}
  \tightlist
  \item
    Validation data could be used for hyperparameter optimization.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{4}
  \tightlist
  \item
    It's recommended that data be shuffled before splitting it into
    \texttt{train} and \texttt{test} sets..
  \end{enumerate}
\end{itemize}

    

    \subsection{Break (5 min)}\label{break-5-min}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/eva-coffee.png}

    \subsection{\texorpdfstring{Cross-validation
{[}\href{https://youtu.be/4cv8VYonepA}{video}{]}}{Cross-validation {[}video{]}}}\label{cross-validation-video}

    \subsubsection{Problems with single train/validation
split}\label{problems-with-single-trainvalidation-split}

\begin{itemize}
\tightlist
\item
  Only using a portion of your data for training and only a portion for
  validation.
\item
  If your dataset is small you might end up with a tiny training and/or
  validation set.
\item
  You might be unlucky with your splits such that they don't align well
  or don't well represent your test data.
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/train-valid-test-split.png}

    \subsubsection{Cross-validation to the
rescue!!}\label{cross-validation-to-the-rescue}

\begin{itemize}
\tightlist
\item
  Cross-validation provides a solution to this problem.
\item
  Split the data into \(k\) folds (\(k>2\), often \(k=10\)). In the
  picture below \(k=4\).
\item
  Each ``fold'' gets a turn at being the validation set.
\item
  Note that cross-validation doesn't shuffle the data; it's done in
  \texttt{train\_test\_split}.
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/cross-validation.png}

    \begin{itemize}
\tightlist
\item
  Each fold gives a score and we usually average our \(k\) results.
\item
  It's better to examine the variation in the scores across folds.\\
\item
  Gives a more \textbf{robust} measure of error on unseen data.
\end{itemize}

    \subsubsection{\texorpdfstring{Cross-validation using
\texttt{scikit-learn}}{Cross-validation using scikit-learn}}\label{cross-validation-using-scikit-learn}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{,} \PY{n}{cross\PYZus{}validate}
\end{Verbatim}
\end{tcolorbox}

    \paragraph{\texorpdfstring{\texttt{cross\_val\_score}}{cross\_val\_score}}\label{cross_val_score}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}
\PY{n}{cv\PYZus{}scores} \PY{o}{=} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\PY{n}{cv\PYZus{}scores}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
array([0.76470588, 0.82352941, 0.70588235, 0.94117647, 0.82352941,
       0.82352941, 0.70588235, 0.9375    , 0.9375    , 0.9375    ])
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{46}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Average cross\PYZhy{}validation score = }\PY{l+s+si}{\PYZob{}}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{cv\PYZus{}scores}\PY{p}{)}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Standard deviation of cross\PYZhy{}validation score = }\PY{l+s+si}{\PYZob{}}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{cv\PYZus{}scores}\PY{p}{)}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Average cross-validation score = 0.84
Standard deviation of cross-validation score = 0.09
    \end{Verbatim}

    Under the hood

\begin{itemize}
\tightlist
\item
  It creates \texttt{cv} folds on the data.
\item
  In each fold, it fits the model on the training portion and scores on
  the validation portion.
\item
  The output is a list of validation scores in each fold.
\end{itemize}

    \paragraph{\texorpdfstring{\texttt{cross\_validate}}{cross\_validate}}\label{cross_validate}

\begin{itemize}
\tightlist
\item
  Similar to \texttt{cross\_val\_score} but more powerful.
\item
  Gives us access to training and validation scores.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}validate}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{scores}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   fit\_time  score\_time  test\_score  train\_score
0  0.003913    0.002363    0.764706     0.913333
1  0.002833    0.001383    0.823529     0.906667
2  0.001658    0.000732    0.705882     0.906667
3  0.001014    0.000641    0.941176     0.900000
4  0.001137    0.000641    0.823529     0.906667
5  0.000948    0.000576    0.823529     0.913333
6  0.000941    0.000595    0.705882     0.920000
7  0.000926    0.000576    0.937500     0.900662
8  0.000921    0.000602    0.937500     0.900662
9  0.000932    0.000670    0.937500     0.900662
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{48}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{scores}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{48}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                    0
fit\_time     0.001522
score\_time   0.000878
test\_score   0.840074
train\_score  0.906865
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Keep in mind that cross-validation does not return a model. It is not a
way to build a model that can be applied to new data. The purpose of
cross-validation is to \textbf{evaluate} how well the model will
generalize to unseen data. \_\_\_

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Note that both \texttt{cross\_val\_score} and \texttt{cross\_validate}
functions do not shuffle the data. Check out
\href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\#sklearn.model_selection.StratifiedKFold}{\texttt{StratifiedKFold}},
where proportions of classes is the same in each fold as they are in the
whole dataset. By default, \texttt{sklearn} uses
\texttt{StratifiedKFold} when carrying out cross-validation for
classification problems. \_\_\_

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{51}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{mglearn\PYZus{}utils}
\PY{n}{mglearn\PYZus{}utils}\PY{o}{.}\PY{n}{plot\PYZus{}cross\PYZus{}validation}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_83_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{Our typical supervised learning set up is as
follows:}\label{our-typical-supervised-learning-set-up-is-as-follows}

\begin{itemize}
\tightlist
\item
  We are given training data with features \texttt{X} and target
  \texttt{y}
\item
  We split the data into train and test portions:
  \texttt{X\_train,\ y\_train,\ X\_test,\ y\_test}
\item
  We carry out hyperparameter optimization using cross-validation on the
  train portion: \texttt{X\_train} and \texttt{y\_train}.
\item
  We assess our best performing model on the test portion:
  \texttt{X\_test} and \texttt{y\_test}.\\
\item
  What we care about is the \textbf{test error}, which tells us how well
  our model can be generalized.
\item
  If this test error is ``reasonable'' we deploy the model which will be
  used on new unseen examples.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{52}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}validate}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{scores}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{52}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   fit\_time  score\_time  test\_score  train\_score
0  0.003835    0.002014    0.875000     1.000000
1  0.002194    0.001434    0.875000     0.992857
2  0.001199    0.000603    0.875000     1.000000
3  0.000912    0.000568    0.687500     1.000000
4  0.000960    0.000565    0.812500     1.000000
5  0.000894    0.000584    0.812500     1.000000
6  0.001006    0.001041    0.866667     0.985816
7  0.001176    0.000631    0.533333     1.000000
8  0.001456    0.000928    0.666667     1.000000
9  0.001229    0.001011    0.733333     1.000000
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{53}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{mean\PYZus{}std\PYZus{}cross\PYZus{}val\PYZus{}scores}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
\PY{+w}{    }\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Returns mean and std of cross validation}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}validate}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}

    \PY{n}{mean\PYZus{}scores} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{scores}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
    \PY{n}{std\PYZus{}scores} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{scores}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
    \PY{n}{out\PYZus{}col} \PY{o}{=} \PY{p}{[}\PY{p}{]}

    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{mean\PYZus{}scores}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{out\PYZus{}col}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZpc{}0.3f (+/\PYZhy{} \PYZpc{}0.3f)}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{mean\PYZus{}scores}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{std\PYZus{}scores}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}

    \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{out\PYZus{}col}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{n}{mean\PYZus{}scores}\PY{o}{.}\PY{n}{index}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{54}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{results} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
\PY{n}{results}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision tree}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{mean\PYZus{}std\PYZus{}cross\PYZus{}val\PYZus{}scores}\PY{p}{(}
    \PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}
\PY{p}{)}
\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{results}\PY{p}{)}\PY{o}{.}\PY{n}{T}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{54}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                        fit\_time         score\_time         test\_score  \textbackslash{}
Decision tree  0.002 (+/- 0.001)  0.001 (+/- 0.000)  0.782 (+/- 0.059)

                     train\_score
Decision tree  0.994 (+/- 0.014)
\end{Verbatim}
\end{tcolorbox}
        
    \begin{itemize}
\tightlist
\item
  How do we know whether this test score is reasonable?
\end{itemize}

    ```\{admonition\} Exercise 3.3: Cross-validation

```

    \subsection{\texorpdfstring{Underfitting, overfitting, the fundamental
trade-off, the golden rule
{[}\href{https://youtu.be/Ihay8yE5KTI}{video}{]}}{Underfitting, overfitting, the fundamental trade-off, the golden rule {[}video{]}}}\label{underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video}

    \subsubsection{Types of errors}\label{types-of-errors}

Imagine that your train and validation errors do not align with each
other. How do you diagnose the problem?

We're going to think about 4 types of errors:

\begin{itemize}
\tightlist
\item
  \(E_\textrm{train}\) is your training error (or mean train error from
  cross-validation).
\item
  \(E_\textrm{valid}\) is your validation error (or mean validation
  error from cross-validation).
\item
  \(E_\textrm{test}\) is your test error.
\item
  \(E_\textrm{best}\) is the best possible error you could get for a
  given problem.
\end{itemize}

    \subsubsection{Underfitting}\label{underfitting}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{55}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}  \PY{c+c1}{\PYZsh{} decision stump}
\PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}validate}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Train error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Train error:   0.188
Validation error:   0.212
    \end{Verbatim}

    \begin{itemize}
\tightlist
\item
  If your model is too simple, like \texttt{DummyClassifier} or
  \texttt{DecisionTreeClassifier} with \texttt{max\_depth=1}, it's not
  going to pick up on some random quirks in the data but it won't even
  capture useful patterns in the training data.
\item
  The model won't be very good in general. Both train and validation
  errors would be high. This is \textbf{underfitting}.
\item
  The gap between train and validation error is going to be lower.
\item
  \(E_\textrm{best} \lt E_\textrm{train} \lesssim E_\textrm{valid}\)
\end{itemize}

    \subsubsection{Overfitting}\label{overfitting}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{56}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
\PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}validate}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Train error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation error:   }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Train error:   0.000
Validation error:   0.220
    \end{Verbatim}

    \begin{itemize}
\tightlist
\item
  If your model is very complex, like a
  \texttt{DecisionTreeClassifier(max\_depth=None)}, then you will learn
  unreliable patterns in order to get every single training example
  correct.
\item
  The training error is going to be very low but there will be a big gap
  between the training error and the validation error. This is
  \textbf{overfitting}.
\item
  In overfitting scenario, usually we'll see:
  \(E_\textrm{train} \lt E_\textrm{best}  \lt E_\textrm{valid}\)
\item
  In general, if \(E_\textrm{train}\) is low, we are likely to be in the
  overfitting scenario. It is fairly common to have at least a bit of
  this.
\end{itemize}

    \begin{itemize}
\tightlist
\item
  So the validation error does not necessarily decrease with the
  training error.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{57}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{results\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}train\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}cv\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{std\PYZus{}cv\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{std\PYZus{}train\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,}
\PY{p}{\PYZcb{}}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}\PY{p}{\PYZcb{}}

\PY{k}{for} \PY{n}{depth} \PY{o+ow}{in} \PY{n}{param\PYZus{}grid}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{:}
    \PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{depth}\PY{p}{)}
    \PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}validate}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{results\PYZus{}dict}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{depth}\PY{p}{)}
    \PY{n}{results\PYZus{}dict}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}cv\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
    \PY{n}{results\PYZus{}dict}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}train\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
    \PY{n}{results\PYZus{}dict}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{std\PYZus{}cv\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}\PY{p}{)}
    \PY{n}{results\PYZus{}dict}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{std\PYZus{}train\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{results\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{results\PYZus{}dict}\PY{p}{)}
\PY{n}{results\PYZus{}df} \PY{o}{=} \PY{n}{results\PYZus{}df}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{58}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{results\PYZus{}df}\PY{p}{[}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}train\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}cv\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{)}\PY{p}{;}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_100_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{itemize}
\tightlist
\item
  Here, for larger depths we observe that the training error is close to
  0 but validation error goes up and down.
\item
  As we make more complex models we start encoding random quirks in the
  data, which are not grounded in reality.\\
\item
  These random quirks do not generalize well to new data.
\item
  This problem of failing to be able to generalize to the validation
  data or test data is called \textbf{overfitting}.
\end{itemize}

    \subsubsection{The ``fundamental tradeoff'' of supervised
learning:}\label{the-fundamental-tradeoff-of-supervised-learning}

\textbf{As you increase model complexity, \(E_\textrm{train}\) tends to
go down but \(E_\textrm{valid}-E_\textrm{train}\) tends to go up.}

    \subsubsection{Bias vs variance
tradeoff}\label{bias-vs-variance-tradeoff}

\begin{itemize}
\tightlist
\item
  The fundamental trade-off is also called the bias/variance tradeoff in
  supervised machine learning.
\end{itemize}

\begin{description}
\tightlist
\item[\textbf{Bias}]
the tendency to consistently learn the same wrong thing (high bias
corresponds to underfitting)
\item[\textbf{Variance}]
the tendency to learn random things irrespective of the real signal
(high variance corresponds to overfitting)
\end{description}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Check out
\href{https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf}{this
article by Pedro Domingos} for some approachable explanation on machine
learning fundamentals and bias-variance tradeoff. \_\_\_

    \subsubsection{How to pick a model that would generalize
better?}\label{how-to-pick-a-model-that-would-generalize-better}

\begin{itemize}
\tightlist
\item
  We want to avoid both underfitting and overfitting.
\item
  We want to be consistent with the training data but we don't to rely
  too much on it.
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/malp_0201.png}

\href{https://learning.oreilly.com/library/view/introduction-to-machine/9781449369880/ch02.html\#relation-of-model-complexity-to-dataset-size}{source}

    \begin{itemize}
\tightlist
\item
  There are many subtleties here and there is no perfect answer but a
  common practice is to pick the model with minimum cross-validation
  error.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{cross\PYZus{}validate\PYZus{}std}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
\PY{+w}{    }\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Like cross\PYZus{}validate, except also gives the standard deviation of the score\PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{res} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cross\PYZus{}validate}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{)}
    \PY{n}{res\PYZus{}mean} \PY{o}{=} \PY{n}{res}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
    \PY{n}{res\PYZus{}mean}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{std\PYZus{}test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{res}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
    \PY{k}{if} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}} \PY{o+ow}{in} \PY{n}{res}\PY{p}{:}
        \PY{n}{res\PYZus{}mean}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{std\PYZus{}train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{res}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{res\PYZus{}mean}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{results\PYZus{}df}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
       mean\_train\_error  mean\_cv\_error  std\_cv\_error  std\_train\_error
depth
1              0.171657       0.211250      0.048378         0.006805
2              0.160258       0.217500      0.048940         0.007316
3              0.142467       0.204583      0.053763         0.022848
4              0.092604       0.204167      0.070907         0.006531
5              0.083338       0.191250      0.067120         0.010650
6              0.066251       0.197500      0.074773         0.012019
7              0.044873       0.210417      0.084641         0.009059
8              0.029909       0.222500      0.092669         0.009422
9              0.020653       0.210000      0.087999         0.010294
10             0.009260       0.228750      0.101387         0.005563
11             0.005699       0.222500      0.105577         0.004264
12             0.003561       0.235833      0.083836         0.004769
13             0.000000       0.235833      0.092687         0.000000
14             0.000000       0.242083      0.086932         0.000000
15             0.000000       0.242083      0.086932         0.000000
\end{Verbatim}
\end{tcolorbox}
        
    \subsubsection{test score vs.~cross-validation
score}\label{test-score-vs.-cross-validation-score}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{61}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{best\PYZus{}depth} \PY{o}{=} \PY{n}{results\PYZus{}df}\PY{o}{.}\PY{n}{index}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{argmin}\PY{p}{(}\PY{n}{results\PYZus{}df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}cv\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{]}
\PY{n+nb}{print}\PY{p}{(}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{The minimum validation error is }\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{ at max\PYZus{}depth = }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}
    \PY{o}{\PYZpc{}} \PY{p}{(}
        \PY{n}{np}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{n}{results\PYZus{}df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}cv\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{n}{best\PYZus{}depth}\PY{p}{,}
    \PY{p}{)}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
The minimum validation error is 0.191 at max\_depth = 5
    \end{Verbatim}

    \begin{itemize}
\tightlist
\item
  Let's pick \texttt{max\_depth}= 5 and try this model on the test set.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{62}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{best\PYZus{}depth}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Error on test set: }\PY{l+s+si}{\PYZob{}}\PY{l+m+mi}{1}\PY{+w}{ }\PY{o}{\PYZhy{}}\PY{+w}{ }\PY{n}{model}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,}\PY{+w}{ }\PY{n}{y\PYZus{}test}\PY{p}{)}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Error on test set: 0.19
    \end{Verbatim}

    \begin{itemize}
\tightlist
\item
  The test error is comparable with the cross-validation error.
\item
  Do we feel confident that this model would give similar performace
  when deployed?
\end{itemize}

    \subsubsection{\texorpdfstring{The golden rule
}{The golden rule }}\label{the-golden-rule}

\begin{itemize}
\tightlist
\item
  Even though we care the most about test error \textbf{THE TEST DATA
  CANNOT INFLUENCE THE TRAINING PHASE IN ANY WAY}.
\item
  We have to be very careful not to violate it while developing our ML
  pipeline.
\item
  Even experts end up breaking it sometimes which leads to misleading
  results and lack of generalization on the real data.
\end{itemize}

    \paragraph{Golden rule violation: Example
1}\label{golden-rule-violation-example-1}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/golden_rule_violation.png}

\ldots{} He attempted to reproduce the research, and found a major flaw:
there was some overlap in the data used to both train and test the
model.

    \paragraph{Golden rule violation: Example
2}\label{golden-rule-violation-example-2}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/golden_rule_violation_2.png}

\ldots{} The Challenge rules state that you must only test your code
twice a week, because there's an element of chance to the results. Baidu
has admitted that it used multiple email accounts to test its code
roughly 200 times in just under six months -- over four times what the
rules allow.

    \paragraph{Golden rule violation: Example
3}\label{golden-rule-violation-example-3}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/GPT-ToM.png}

A few months ago, debates around whether contemporary large language
models (LLMs) are showing theory of mind capabilities or not sparked the
media\ldots{}

\ldots We show that NONE of the existing LLMs show signs of coherent ToM
capabilities, including GPT-4.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{\emph{What happened?}} Common ToM test questions are on the
internet, and were in the training set of the LLMs, generating hilarious
cases of over-fitting. \_\_\_

    \subsubsection{How can we avoid violating golden
rule?}\label{how-can-we-avoid-violating-golden-rule}

\begin{itemize}
\tightlist
\item
  Recall that when we split data, we put our test set in an imaginary
  vault.
\end{itemize}

\includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/train-test-split.png}

    \subsubsection{Here is the workflow we'll generally
follow.}\label{here-is-the-workflow-well-generally-follow.}

\begin{itemize}
\tightlist
\item
  \textbf{Splitting}: Before doing anything, split the data \texttt{X}
  and \texttt{y} into \texttt{X\_train}, \texttt{X\_test},
  \texttt{y\_train}, \texttt{y\_test} or \texttt{train\_df} and
  \texttt{test\_df} using \texttt{train\_test\_split}.
\item
  \textbf{Select the best model using cross-validation}: Use
  \texttt{cross\_validate} with \texttt{return\_train\_score\ =\ True}
  so that we can get access to training scores in each fold. (If we want
  to plot train vs validation error plots, for instance.)
\item
  \textbf{Scoring on test data}: Finally score on the test data with the
  chosen hyperparameters to examine the generalization performance.
\end{itemize}

\textbf{Again, there are many subtleties here we'll discuss the golden
rule multiple times throughout the course.}

    

    \subsection{â“â“ Questions for you}\label{questions-for-you}

    \subsubsection{iClicker Exercise 3.2}\label{iclicker-exercise-3.2}

\textbf{iClicker cloud join link: https://join.iclicker.com/WMSX}

\textbf{Select all of the following statements which are TRUE.}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \tightlist
  \item
    \(k\)-fold cross-validation calls fit \(k\) times.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{1}
  \tightlist
  \item
    We use cross-validation to get a more robust estimate of model
    performance.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{2}
  \tightlist
  \item
    If the mean train accuracy is much higher than the mean
    cross-validation accuracy it's likely to be a case of overfitting.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{3}
  \tightlist
  \item
    The fundamental tradeoff of ML states that as training error goes
    down, validation error goes up.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{(\Alph{enumi})}
  \setcounter{enumi}{4}
  \tightlist
  \item
    A decision stump on a complicated classification problem is likely
    to underfit.
  \end{enumerate}
\end{itemize}

    

    \subsection{Summary and reflection}\label{summary-and-reflection}

    \subsubsection{What did we learn today?}\label{what-did-we-learn-today}

\begin{itemize}
\tightlist
\item
  Importance of generalization in supervised machine learning
\item
  Data splitting as a way to approximate generalization error
\item
  Train, test, validation, deployment data
\item
  Cross-validation
\item
  A typical sequence of steps to train supervised machine learning
  models

  \begin{itemize}
  \tightlist
  \item
    training the model on the train split
  \item
    tuning hyperparamters using the validation split
  \item
    checking the generalization performance on the test split
  \end{itemize}
\item
  Overfitting, underfitting, the fundamental tradeoff, and the golden
  rule.
\end{itemize}

    \subsubsection{Reflection}\label{reflection}

Write your reflections (takeaways, struggle points, and general
comments) on this material in
\href{https://docs.google.com/document/d/1LWiR7dzzNNwOJR72LWgC25priLXGdyxEq9FWBia3wmw/edit?usp=sharing}{our
reflection Google Document} so that I'll try to address those points in
the next lecture.

    \subsubsection{Coming up \ldots{}}\label{coming-up}

\begin{itemize}
\tightlist
\item
  KNNs, SVM RBFs
\item
  Preprocessing

  \begin{itemize}
  \tightlist
  \item
    Imputation
  \item
    Scaling
  \item
    One-hot encoding
  \item
    \texttt{sklearn} pipelines
  \end{itemize}
\end{itemize}

    \includegraphics{/Users/charleenchu/Desktop/school/cpsc330-2023W2/lectures/img/eva-seeyou.png}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
